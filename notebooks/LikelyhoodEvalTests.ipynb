{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import numpy as np\n",
    "import scipy.io as scio\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "import quat_math as qm\n",
    "from generic_pose.utils import to_np, to_var\n",
    "\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "pylab.rcParams['figure.figsize'] = 20, 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root = './datasets/ycb/YCB_Video_Dataset'\n",
    "model_checkpoint = 'trained_checkpoints/ycb/pose_model_26_0.012863246640872631.pth'\n",
    "refine_model_checkpoint = 'trained_checkpoints/ycb/pose_refine_model_69_0.009449292959118935.pth'\n",
    "valid_model_checkpoint = '../DenseFusionOld/DenseFusion/trained_models/ycb/pose_model_34_0.025648579025031315.pth'\n",
    "\n",
    "#dataset_config_dir = 'datasets/ycb/dataset_config'\n",
    "dataset_config_dir = '../DenseFusionOld/DenseFusion/datasets/ycb/dataset_config'\n",
    "test_filenames = '{0}/test_data_list.txt'.format(dataset_config_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dense_fusion.evaluate import DenseFusionEstimator, preprocessData\n",
    "from dense_fusion.data_processing import preprocessPoseCNNMetaData\n",
    "\n",
    "num_points = 1000\n",
    "num_obj = 21\n",
    "\n",
    "#df_estimator = DenseFusionEstimator(num_points, num_obj, model_checkpoint)\n",
    "df_estimator = DenseFusionEstimator(num_points, num_obj, valid_model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dense_fusion.evaluate_likelihood import getYCBClassData, getYCBGroundtruth\n",
    "\n",
    "with open(test_filenames) as f:\n",
    "    file_list = f.read().split()\n",
    "class_list, model_points = getYCBClassData(dataset_root)\n",
    "data_prefix = '{0}/{1}'.format(dataset_root, file_list[0])\n",
    "\n",
    "img = Image.open('{}-color.png'.format(data_prefix))\n",
    "depth = np.array(Image.open('{}-depth.png'.format(data_prefix)))\n",
    "pose_meta = scio.loadmat('{}-meta.mat'.format(data_prefix))\n",
    "posecnn_meta = scio.loadmat('{}-posecnn.mat'.format(data_prefix))\n",
    "object_classes = set(pose_meta['cls_indexes'].flat) & \\\n",
    "                    set(posecnn_meta['rois'][:,1:2].flatten().astype(int))\n",
    "cls_idx = list(object_classes)[0]\n",
    "obj_idx = np.nonzero(posecnn_meta['rois'][:,1].astype(int) == cls_idx)[0][0]\n",
    "mask, bbox, object_label = preprocessPoseCNNMetaData(posecnn_meta, obj_idx)\n",
    "\n",
    "q_gt, _ = getYCBGroundtruth(pose_meta, posecnn_meta, obj_idx)\n",
    "q_gt = torch.Tensor(q_gt).unsqueeze(0)\n",
    "if(torch.cuda.is_available()):\n",
    "    q_gt = q_gt.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6444], device='cuda:0', grad_fn=<SumBackward2>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from object_pose_utils.utils.grid_interpolation import BinghamInterpolation\n",
    "\n",
    "pred_r, pred_t, pred_c = df_estimator(img, depth, mask, bbox, object_label, return_all = True)[3:6]\n",
    "pred_r = pred_r[0,:,[1,2,3,0]]\n",
    "pred_c.shape\n",
    "bingham_interp = BinghamInterpolation(vertices = to_np(pred_r), \n",
    "                                      values = pred_c, \n",
    "                                      sigma=10)\n",
    "\n",
    "bingham_interp(q_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: tensor([-0.4431], device='cuda:0', grad_fn=<LogBackward>),\n",
       " 5: tensor([1.5384], device='cuda:0', grad_fn=<LogBackward>),\n",
       " 7: tensor([1.6409], device='cuda:0', grad_fn=<LogBackward>),\n",
       " 8: tensor([1.4627], device='cuda:0', grad_fn=<LogBackward>),\n",
       " 13: tensor([-8.3545], device='cuda:0', grad_fn=<LogBackward>),\n",
       " 18: tensor([-0.4136], device='cuda:0', grad_fn=<LogBackward>),\n",
       " 21: tensor([-3.4655], device='cuda:0', grad_fn=<LogBackward>)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dense_fusion.evaluate_likelihood import evaluateYCBEvery\n",
    "\n",
    "evaluateYCBEvery(df_estimator, data_prefix, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'likelihoods' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-857781d89ef0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmean_likelihood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlikelihoods\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mmean_likelihood\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'likelihoods' is not defined"
     ]
    }
   ],
   "source": [
    "mean_likelihood = 0\n",
    "n = 0\n",
    "for v in likelihoods.values():\n",
    "    mean_likelihood += np.sum(v)\n",
    "    n += len(v)\n",
    "mean_likelihood /= n\n",
    "\n",
    "print(mean_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "eta_values = sio.loadmat('../object_pose_utils/src/object_pose_utils/utils/bingham_normalization.mat')\n",
    "print(eta_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from dense_fusion.evaluate_likelihood import subRandomSigmaSearch\n",
    "\n",
    "with open(test_filenames) as f:\n",
    "    file_list = f.read().split()\n",
    "subRandomSigmaSearch(df_estimator, dataset_root, file_list, \n",
    "                     sigma_lims = [0, 30],\n",
    "                     num_samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from object_pose_utils.utils.pose_processing import getGaussianKernal\n",
    "\n",
    "print(torch.as_tensor([q_center, q_center1]).shape)\n",
    "print(torch.Tensor(q).shape)\n",
    "sigma = np.pi/9\n",
    "\n",
    "getGaussianKernal(torch.Tensor(q[0:3]).float(), \n",
    "                  torch.as_tensor([q_center, q_center1]).float(), \n",
    "                  sigma=sigma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from object_pose_utils.utils import to_np\n",
    "from object_pose_utils.utils.grid_interpolation import GaussianInterpolation, BinghamInterpolation\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "q_center = np.random.randn(4)\n",
    "q_center /= np.linalg.norm(q_center)\n",
    "\n",
    "w = [1]\n",
    "\n",
    "N = 100\n",
    "q = np.random.randn(4,N)\n",
    "q = (q / np.linalg.norm(q, axis=0)).T\n",
    "#pbs = []\n",
    "#pgs = []\n",
    "#sigma_multipliers = np.linspace(1,100, 1000)\n",
    "#sigma_multipliers = np.logspace(-2,2, 1000)\n",
    "#for multi in sigma_multipliers:\n",
    "sigma_gauss = np.pi/9\n",
    "#sigma_bingham = sigma_gauss*2.8474391664672476\n",
    "sigma_bingham = sigma_gauss\n",
    "\n",
    "\n",
    "binghamInterp = BinghamInterpolation(vertices = [q_center], \n",
    "                                     values = torch.Tensor(w), \n",
    "                                     sigma=sigma_bingham)\n",
    "p_bingham = to_np(binghamInterp(torch.Tensor(q).cuda()))\n",
    "\n",
    "#print(p_bingham)\n",
    "#pbs.append(p_bingham)\n",
    "\n",
    "gaussianInterp = GaussianInterpolation(vertices = [q_center], \n",
    "                                       values = w, \n",
    "                                       sigma=sigma_gauss)\n",
    "\n",
    "\n",
    "\n",
    "p_gauss = to_np(gaussianInterp(torch.Tensor(q).cuda()))\n",
    "#print(p_gauss)\n",
    "plt.plot(p_gauss, label = 'Gaussian')\n",
    "plt.plot(p_bingham, label = 'Bingham')\n",
    "plt.legend()\n",
    "#pgs.append(p_gauss)\n",
    "#plt.plot(sigma_multipliers, pbs, label = 'Bingham')\n",
    "#plt.plot(sigma_multipliers, pgs, label = 'Gaussian')\n",
    "#diff = np.log(np.array(pgs)/np.array(pbs))\n",
    "#diff = np.abs(np.array(pgs)-np.array(pbs)) / np.array(pgs)\n",
    "#print(np.nonzero(diff > 0)[0][0])\n",
    "#plt.plot(sigma_multipliers, diff)\n",
    "#plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "min_idx = np.argmin(diff, axis = 0)\n",
    "min_val = np.min(diff, axis = 0)\n",
    "\n",
    "min_idx = min_idx[np.bitwise_and(min_idx > 0, min_val < .5)]\n",
    "\n",
    "print(max(sigma_multipliers[min_idx]))\n",
    "plt.hist(sigma_multipliers[min_idx], 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (bpy)",
   "language": "python",
   "name": "bpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
